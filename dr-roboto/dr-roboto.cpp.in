/*
  File: dr-roboto.cpp
  Author: Dagim Sisay <dagiopia@gmail.com>
  License: AGPL
  Date: May, 2018
*/

#define YES_RPI 1
#define NO_RPI 0

#define _DR_ROBOTO_RPI_ @ON_RPI_3@_RPI


#include <stdio.h>
#include <vector>
#include <unistd.h>


#if _DR_ROBOTO_RPI_
    #include "sense/vision/RaspiVision.hpp"
#else //_DR_ROBOTO_RPI
    #include "sense/vision/Vision.hpp"
#endif
#include "act/audio/FestivalTTS.hpp"


//debug consts 
#define _NEED_GUI_
#define _NEED_TIME_INFO_


// opencog headers
#define HAVE_GUILE

#include <opencog/atomspace/AtomSpace.h>
#include <opencog/truthvalue/TruthValue.h>
#include <opencog/truthvalue/AttentionValue.h>

#include <opencog/atoms/proto/FloatValue.h>
#include <opencog/atoms/proto/LinkValue.h>
#include <opencog/atoms/proto/StringValue.h>

#include <opencog/guile/SchemePrimitive.h>


#define SCALE 0.1


using namespace std;
using namespace opencog;


class DrRoboto
{
	private:
		AtomSpace *_as;
		bool ok;
		
		#if _DR_ROBOTO_RPI_
			RaspiCamCapture *cap;
		#else //_DR_ROBOTO_RPI_
			CamCapture *cap;
		#endif //_DR_ROBOTO_RPI_

		ITColor2Gray c2g;
		ITEqualizeHist eh;
		ITDetectFace fcd;
		ITDetectSmile smd;
		FacialLandMark flm;
		ITDetectHand dh;
		FingersCount fc;
		DSaliency sal_d;
		FestivalTTS tts;

	public:
		/* 
			XXX don't know if this is the right way to do it. 
			The AS is shared b/n this program and the guile instance once this module 
			is loaded and init_as is called from guile with the AS address as arg. 
					(init_as (cog-atomspace))   ; this should be called first
			Also the AS is just copied. 
		*/
		DrRoboto();
		~DrRoboto();
		void init_as(AtomSpace *as) { _as = as; ok = true;}
		
		//sensor functions
		void start_sense();
		void stop_sense();
};


extern "C" {
  void init_dr_roboto();
};


DrRoboto::DrRoboto() : c2g("c2g") , eh("eh") , fcd("fcd") , smd("smd") , 
							  dh("dh") , fc("fc") , sal_d(SAL_STATIC, SAL_FINE_GRAINED)
{
	ok = false;
	#ifdef _NEED_TIME_INFO_
		//avg_nh = avg_oh = avg_of = avg_nf = avg_time_pf = 0;
		//oh = nh = of = nf = n_f = 0;
	#endif //_NEED_TIME_INFO_

	#if _DR_ROBOTO_RPI_
		cap = new RaspiCamCapture("cap", 320, 240, 20);
	#else //_DR_ROBOTO_RPI_
		cap = new CamCapture("cap", 320, 240, 0, 20);
	#endif //_DR_ROBOTO_RPI_

	/*
	c2g = new ITColor2Gray("c2g");
	eh = new ITEqualizeHist("eh");
	fcd = new ITDetectFace("fcd");
	smd = new ITDetectSmile("smd");
	dh = new ITDetectHand("dh");
	fc = new FingersCount(true);
	sal_d = new DSaliency(SAL_STATIC, SAL_FINE_GRAINED); 
	*/
} 

DrRoboto::~DrRoboto() {}


void DrRoboto::start_sense()
{
	cv::Mat frame, img, gr, he;
	std::vector<cv::Rect> faces, smile, hands;
	facial_lms f_lms;
	cv::Point2d cent;
	std::string str;
	Handle h;
	Handle hl;
	Handle sm = _as->add_node(PREDICATE_NODE, "smile");
	Handle lk = _as->add_node(PREDICATE_NODE, "look");
	Handle ey = _as->add_node(CONCEPT_NODE, "eyes");
	Handle hh = _as->add_node(CONCEPT_NODE, "hand");
	Handle fi = _as->add_node(CONCEPT_NODE, "fingers");
	Handle pos_h = _as->add_node(CONCEPT_NODE, "position");
	Handle sen_h = _as->add_node(CONCEPT_NODE, "sense");
	Handle rate_h = _as->add_node(CONCEPT_NODE, "rate");
	//sen_h->setValue(rate_h, createFloatValue(1000)); //u-secs to delay sensor

	ProtoAtomPtr pap;
	
	while(ok) {
		frame = cap->getCurrentFrame();
		gr = c2g.Transform(frame);
		he = eh.Transform(gr);
		faces = fcd.Transform(he);
		for(size_t i = 0; i < faces.size(); i++) {
			str = "face_" + std::to_string(i);
			h = _as->add_node(CONCEPT_NODE, str.c_str());
			smile = smd.Transform(he(faces[i])); //only check on the smaller face region 
			if(!smile.empty())
				pap = createFloatValue(1.0);
			else 
				pap = createFloatValue(0.0);
			h->setValue(sm, pap);
			/*
				^ this is 
					Valuation
						PredicateNode "smile"
						ConceptNode "face_x"
						FloatValue x.x
			*/

			// facial lms
			flm.get_lm_points(frame, faces[i], f_lms);
			/*
				TODO emo detector here... should just be a function that returns
				the detected emo along with confidence (if it's possible)

				once the emo is detected, make a link to the current face 
				with the conceptnode for the emo type and set stv based on 
				confidence (if possible) 
					Link
						ConceptNode "face_x"
						ConceptNode "emotion_x"
						STV x.y x.z
			*/
			
			// TODO do eye state here
		}

		/*
			salient point
				Valuation
					PredicateNode "look"
					ConceptNode "eyes"
					LinkValue
						FloatValue X
						FloatValue Y
		*/
		cent = sal_d.sal_point(gr, gr);
		pap = createLinkValue(std::vector<ProtoAtomPtr>({createFloatValue((float)cent.x),
																		createFloatValue((float)cent.y)}));
		ey->setValue(lk, pap);

		/*
			hand detection and finger counting
			
			** hand detection **
			Valuation
				PredicateNode "position"
				ConceptNode "hand"
				LinkValue
					FloatValue X
					FloatValue Y

			** finger count **
			Valuation
				ConceptNode "hand_x"
				ConceptNode "fingers"
				FloatValue X
		*/
		cv::threshold(he, he, 70, 255, CV_THRESH_BINARY_INV | CV_THRESH_OTSU);
		hands = dh.Transform(he);
		for(size_t idx = 0; idx < hands.size(); idx++) {
			img = cv::Mat(he, cv::Rect(hands[idx].x - hands[idx].x*SCALE,
												hands[idx].y - hands[idx].y*SCALE,
												hands[idx].width + hands[idx].width*SCALE,
												hands[idx].height + hands[idx].height*SCALE));
			
			str = "hand_" + std::to_string(idx);
			h = _as->add_node(CONCEPT_NODE, str.c_str());
			
			pap = createLinkValue(
						std::vector<ProtoAtomPtr>({
								createFloatValue((float)hands[idx].x+(hands[idx].width/2)),
								createFloatValue((float)hands[idx].y+(hands[idx].height/2))}));
			h->setValue(pos_h, pap);
								
			pap = createFloatValue((float)fc.num_fingers(img));
			h->setValue(fi, pap);
		}

		usleep(10000);
	} //while ok
}


void DrRoboto::stop_sense()
{
	ok = false;
}

/*
float avg_time_pf, en_time, acc, avg_oh, avg_nh, avg_nf, avg_of;
uint64_t st_time;
int n_f, nh, oh, nf, of;
std::string ret;
std::string text = "";


void print_report()
{       
    avg_time_pf = acc / n_f;
    avg_nh /= nh;
    avg_oh /= oh;
    avg_of /= of;
    avg_nf /= nf;
    printf("\nAverage Time per Frame (no Face): %f\n", avg_nf);
    printf("Average Time per Frame (on Face): %f\n", avg_of);
    printf("Average Time per Frame (no Hand): %f\n", avg_nh);
    printf("Average Time per Frame (on Hand): %f\n", avg_oh);
    printf("Average Time per Frame: %f\n\n", avg_time_pf);
}



void say(char *data)
{
    tts.setSpeaker(FestivalTTS::speaker::DON);
    text = data;
    //printf("Speech output: %s\n", data);
    tts.speak(text.c_str());
}

void scm_say(SCM txt)
{
    say(scm_to_locale_string(txt));
}
*/

void init_dr_roboto()
{
	DrRoboto *dr = new DrRoboto();
	define_scheme_primitive("c-init-as", &DrRoboto::init_as, dr);
	define_scheme_primitive("c-start-sensors", &DrRoboto::start_sense, dr);
	define_scheme_primitive("c-stop-sensors", &DrRoboto::stop_sense, dr);
}
